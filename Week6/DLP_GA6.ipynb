{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOlTDBGruiHRT0aOJDjgg6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dxvsh/LearningPytorch/blob/main/Week6/DLP_GA6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DLP GA6"
      ],
      "metadata": {
        "id": "a0y_5o4Pqh_k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Necessary Libraries"
      ],
      "metadata": {
        "id": "jkMs3fAPqkF4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Klb-r2TYpt8j"
      },
      "outputs": [],
      "source": [
        "!pip install speechbrain==0.5.16 faster_whisper pyannote.audio whisper moviepy ctranslate2==4.4.0 > /dev/null"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Neccessary Imports"
      ],
      "metadata": {
        "id": "iHsEGBcettIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa, traceback\n",
        "from faster_whisper import WhisperModel\n",
        "import torch\n",
        "import whisper\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re, time, os, datetime\n",
        "from sklearn.cluster import AgglomerativeClustering, KMeans\n",
        "from pyannote.audio.pipelines.speaker_verification import PretrainedSpeakerEmbedding\n",
        "from pyannote.audio import Audio\n",
        "from pyannote.core import Segment\n",
        "import speechbrain\n",
        "from scipy.spatial.distance import cdist"
      ],
      "metadata": {
        "id": "-uQVDfWgttW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare Audio File**\n",
        "\n",
        "Upload the audio file **(Test 1.mp3)** into the environment. Convert the audio from MP3 to WAV format with a sample rate of 16 kHz and set it to mono. Use 16-bit little-endian PCM (Pulse Code Modulation) encoding. The converted file will be used for processing.\n",
        "\n",
        "Click [here](https://drive.google.com/file/d/1sJUZe9320zQNON3o0dXV9UtmYkqsxlU8/view) to view the audio file."
      ],
      "metadata": {
        "id": "CwXwmqjQqPXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Speaker Diarization Steps**\n",
        "\n",
        "1. Load the converted audio file using the librosa library with a sample rate of 16 kHz and set it to mono and prepare it for processing.\n",
        "\n",
        "2. Initialize the Whisper model from faster whisper for transcription. Various model options are available, such as **tiny, base, small, medium, large-v1, and large-v2**. For this work, we will use base.\n",
        "\n",
        "3. Load the pretrained speaker embedding model using **speechbrain/spkrec-ecapa-voxceleb**. This model will be used to extract speaker embeddings from the audio.\n",
        "\n",
        "4. Transcribe the audio using the Whisper model from faster whisper, dividing it into segments based on time. for transcribe to 'en' language, use the following options: beam_size=5 and best_of=5\n",
        "\n",
        "5. For each audio segment, generate speaker embeddings and store them.\n",
        "\n",
        "6. Use clustering (KMeans) to group the segments by speaker. Set the number of speakers to three.\n",
        "\n",
        "7. Assign speaker labels to each segment and compute the distances between speaker clusters to differentiate them.\n"
      ],
      "metadata": {
        "id": "JKVNDBZaqs6T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "Download the given audio:"
      ],
      "metadata": {
        "id": "35kgyA9bsNqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 1sJUZe9320zQNON3o0dXV9UtmYkqsxlU8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0u7wCB7osGq-",
        "outputId": "e1874a4d-9d9f-4446-ab43-aa003157d80a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1sJUZe9320zQNON3o0dXV9UtmYkqsxlU8\n",
            "To: /content/TEST-1.mp3\n",
            "\r  0% 0.00/1.94M [00:00<?, ?B/s]\r100% 1.94M/1.94M [00:00<00:00, 57.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio_file_path = '/content/TEST-1.mp3'"
      ],
      "metadata": {
        "id": "S0glgmvxsWzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.** Find the number of samples of the original audio file when loaded as a numpy array.\n",
        "\n",
        "> **Note**: I'm not processing the audio into wav first and using it directly as given because the question asks about the original audio.\n",
        "\n",
        "> By default, `librosa` loads the audio using sample rate, `sr=22050`, you can set `sr=None` to preserve the original sampling rate."
      ],
      "metadata": {
        "id": "C5mzos89q2Lm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the audio file using librosa\n",
        "audio, sr = librosa.load(audio_file_path, sr=None, mono=False)  # sr=None preserves original sample rate\n",
        "\n",
        "print(audio.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dmH4FP9qG_b",
        "outputId": "c4f49aec-c622-4b6d-a9e7-7e4a15777df3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 5334016)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This indicates that the given audio is dual channels. There are 2 channels. And each channel has **5334016** samples."
      ],
      "metadata": {
        "id": "LVQmG_Ygz8TA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2.** What is the sampling rate of the original audio?\n",
        "\n",
        "> For checking the original sampling rate, we need to set `sr=None` while loading the audio using `librosa` otherwise it loads the audio using `sr=22050` and will report *that* as the sampling rate."
      ],
      "metadata": {
        "id": "PoQ8RtR3q7Mf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sampling rate of the original audio\n",
        "sr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beyhTQGDzCWi",
        "outputId": "8bbc1ecc-132c-417f-e9cf-79a225d68328"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "44100"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.** How many channels are present in the original audio?\n",
        "\n",
        "**A.** We already saw that there are 2 channels in the orignal audio. But we can further check our answers using `ffmpeg`"
      ],
      "metadata": {
        "id": "ckXNEJ6wq-t6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ffprobe -i \"{audio_file_path}\" -show_streams -select_streams a:0 -v 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkCGVPHorA9W",
        "outputId": "3e3e8bcc-238a-473a-86bd-6dfee97ebb1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[STREAM]\n",
            "index=0\n",
            "codec_name=mp3\n",
            "codec_long_name=MP3 (MPEG audio layer 3)\n",
            "profile=unknown\n",
            "codec_type=audio\n",
            "codec_tag_string=[0][0][0][0]\n",
            "codec_tag=0x0000\n",
            "sample_fmt=fltp\n",
            "sample_rate=44100\n",
            "channels=2\n",
            "channel_layout=stereo\n",
            "bits_per_sample=0\n",
            "id=N/A\n",
            "r_frame_rate=0/0\n",
            "avg_frame_rate=0/0\n",
            "time_base=1/14112000\n",
            "start_pts=353600\n",
            "start_time=0.025057\n",
            "duration_ts=1707540480\n",
            "duration=120.999184\n",
            "bit_rate=128000\n",
            "max_bit_rate=N/A\n",
            "bits_per_raw_sample=N/A\n",
            "nb_frames=N/A\n",
            "nb_read_frames=N/A\n",
            "nb_read_packets=N/A\n",
            "DISPOSITION:default=0\n",
            "DISPOSITION:dub=0\n",
            "DISPOSITION:original=0\n",
            "DISPOSITION:comment=0\n",
            "DISPOSITION:lyrics=0\n",
            "DISPOSITION:karaoke=0\n",
            "DISPOSITION:forced=0\n",
            "DISPOSITION:hearing_impaired=0\n",
            "DISPOSITION:visual_impaired=0\n",
            "DISPOSITION:clean_effects=0\n",
            "DISPOSITION:attached_pic=0\n",
            "DISPOSITION:timed_thumbnails=0\n",
            "TAG:encoder=Lavc60.3.\n",
            "[/STREAM]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that our answers are correct as per `ffmpeg` as well. According to the above output:\n",
        "\n",
        "- sample_rate=44100\n",
        "- channels=2\n",
        "- channel_layout=stereo\n",
        "\n",
        "which matches what we got."
      ],
      "metadata": {
        "id": "5bWl0Xaf26hq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4.** What is the meaning of ”le” in the ”pcm s16le”?\n",
        "\n",
        "\n",
        "- [ ] low endian\n",
        "- [x] little endian\n",
        "- [ ] local endian\n",
        "- [ ] long endian\n"
      ],
      "metadata": {
        "id": "7ru7wF6jrCjW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5.** While loading the model using **WhisperModel** from the **faster_whisper** package, what argument is needed to quantize the model to 8-bit precision?\n",
        "\n",
        "\n",
        "- [x] compute_type\n",
        "- [ ] precision_type\n",
        "- [ ] quantization_type\n",
        "- [ ] download_type\n"
      ],
      "metadata": {
        "id": "KdMqeM-urJtm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6.** How many segments are returned by the Whisper model for the given audio?"
      ],
      "metadata": {
        "id": "ECd58ZcWrQ1F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First convert the mp3 audio to wav"
      ],
      "metadata": {
        "id": "uQKgOV01myu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -i \"{audio_file_path}\" -ar 16000 -ac 1 -c:a pcm_s16le \"{audio_file_path[:-4]}.wav\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdJnYe_Cm25D",
        "outputId": "8892e0bc-ff6d-4038-bb40-069674735389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ffmpeg version 4.4.2-0ubuntu0.22.04.1 Copyright (c) 2000-2021 the FFmpeg developers\n",
            "  built with gcc 11 (Ubuntu 11.2.0-19ubuntu1)\n",
            "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
            "  libavutil      56. 70.100 / 56. 70.100\n",
            "  libavcodec     58.134.100 / 58.134.100\n",
            "  libavformat    58. 76.100 / 58. 76.100\n",
            "  libavdevice    58. 13.100 / 58. 13.100\n",
            "  libavfilter     7.110.100 /  7.110.100\n",
            "  libswscale      5.  9.100 /  5.  9.100\n",
            "  libswresample   3.  9.100 /  3.  9.100\n",
            "  libpostproc    55.  9.100 / 55.  9.100\n",
            "Input #0, mp3, from '/content/TEST-1.mp3':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    title           : clideo.com\n",
            "    encoder         : Lavf60.3.100\n",
            "  Duration: 00:02:01.00, start: 0.025057, bitrate: 128 kb/s\n",
            "  Stream #0:0: Audio: mp3, 44100 Hz, stereo, fltp, 128 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc60.3.\n",
            "Stream mapping:\n",
            "  Stream #0:0 -> #0:0 (mp3 (mp3float) -> pcm_s16le (native))\n",
            "Press [q] to stop, [?] for help\n",
            "Output #0, wav, to '/content/TEST-1.wav':\n",
            "  Metadata:\n",
            "    major_brand     : isom\n",
            "    minor_version   : 512\n",
            "    compatible_brands: isomiso2avc1mp41\n",
            "    INAM            : clideo.com\n",
            "    ISFT            : Lavf58.76.100\n",
            "  Stream #0:0: Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s\n",
            "    Metadata:\n",
            "      encoder         : Lavc58.134.100 pcm_s16le\n",
            "size=       0kB time=00:00:00.00 bitrate=N/A speed=N/A    \rsize=    3780kB time=00:02:00.95 bitrate= 256.0kbits/s speed= 306x    \n",
            "video:0kB audio:3780kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.002532%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we've got the wav file now:\n",
        "\n",
        "audio_file_path = '/content/TEST-1.wav'"
      ],
      "metadata": {
        "id": "KK_mI512rHcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Available Whisper models\n",
        "WHISPER_MODELS = [\"tiny\", \"base\", \"small\", \"medium\", \"large-v1\", \"large-v2\"]\n",
        "\n",
        "# Initialize the speaker embedding model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "embedding_model = PretrainedSpeakerEmbedding(\n",
        "    \"speechbrain/spkrec-ecapa-voxceleb\",\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "id": "Qn9-_GPxnHHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_time(seconds):\n",
        "    \"\"\"Converts seconds to readable time format.\"\"\"\n",
        "    return datetime.timedelta(seconds=round(seconds))\n",
        "\n",
        "# for example, it properly converts 125 sec to 02:05\n",
        "print(convert_time(125))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTf4c3wOnLmY",
        "outputId": "a4e88cdc-b4a3-45d0-c9a1-8bada7e4e453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:02:05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_audio(audio_file):\n",
        "    \"\"\"Loads audio file and get its duration.\"\"\"\n",
        "    audio_data, sample_rate = librosa.load(audio_file, mono=True, sr=16000)\n",
        "    duration = len(audio_data) / sample_rate\n",
        "    return duration, sample_rate\n",
        "\n",
        "load_audio(audio_file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXh_JJdWnPWR",
        "outputId": "dce15f3e-143a-4eaf-e03a-abc760968175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(120.95275, 16000)"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_audio(audio_file, whisper_model=\"base\"):\n",
        "    \"\"\"Transcribe audio using Whisper and get time segments.\"\"\"\n",
        "\n",
        "    # Initialize Whisper model to use\n",
        "    model = WhisperModel(whisper_model, compute_type=\"int8\")\n",
        "\n",
        "    # Get audio duration\n",
        "    duration, _ = load_audio(audio_file)\n",
        "\n",
        "    # Transcribe audio\n",
        "    options = dict(language='en', beam_size=5, best_of=5)\n",
        "    segments_raw, _ = model.transcribe(audio_file, task=\"transcribe\", **options)\n",
        "\n",
        "    # Convert to simplified format\n",
        "    segments = [] # here we'll keep track of the different segments (the start and end time of each segment)\n",
        "    for segment_chunk in segments_raw:\n",
        "        chunk = {\"start\": segment_chunk.start, \"end\": segment_chunk.end}\n",
        "        segments.append(chunk)\n",
        "\n",
        "        # just printing for my reference how the transcription looks\n",
        "        print(f\"{segment_chunk.start} - {segment_chunk.end} :  {segment_chunk.text}\")\n",
        "\n",
        "    return segments, duration"
      ],
      "metadata": {
        "id": "3HCu3ltxnX9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segments, duration = transcribe_audio(audio_file_path, \"base\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfxaGUDindU0",
        "outputId": "ab347449-79a1-42d0-b73a-e93b1a0e210f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 - 3.92 :   Let's talk about music. How often do you listen to music?\n",
            "3.92 - 7.04 :   I think I listen to music mostly when I'm driving.\n",
            "7.04 - 12.8 :   I think it puts me in such a good mood when I'm out there on a drive and I play my favorite\n",
            "12.8 - 20.96 :   music. I'm usually into Afro music a lot, hip-hop and Afro and R&B, so I prefer listening to music when\n",
            "20.96 - 26.8 :   I'm driving or sometimes when I'm working out at the gym, something like that.\n",
            "26.8 - 31.12 :   Is music an important subject in schools in your country?\n",
            "31.12 - 37.2 :   In schools in my country, it is because I'm from India, so in India,\n",
            "37.2 - 43.6 :   music and dance and expressing our emotions as usually through music and dancing.\n",
            "43.6 - 50.64 :   So in every school they teach classical music or they have a subject where there is something\n",
            "50.64 - 54.24 :   about music usually, so I think it is important.\n",
            "54.24 - 56.56 :   Do you ever go to live concerts?\n",
            "56.56 - 62.96 :   Oh, I've been to three concerts and three of them are my favorite artists and it was actually on my\n",
            "63.84 - 68.32000000000001 :   wish list and I made it happen and it was one of the best experiences.\n",
            "69.2 - 73.6 :   And in live concerts, it's a lot different than you would imagine.\n",
            "74.48 - 80.64 :   Just have to keep your energy straight and it's like you can't believe it's happening.\n",
            "81.44 - 86.32000000000001 :   Now let's talk about magazines and newspapers. Do you prefer to read magazines\n",
            "86.32000000000001 - 94.08000000000001 :   or newspapers? Definitely magazines, mostly on topics of fashion or interior design.\n",
            "94.08000000000001 - 98.32000000000001 :   This is what I really like because I like to see creative sides all from all over the world.\n",
            "98.32000000000001 - 104.48 :   I like to see what people are talking about, what's new and what's trending and I like to learn,\n",
            "104.48 - 109.12 :   like I like to have knowledge of things of like what is this called or what is that called?\n",
            "109.12 - 112.48 :   Because usually when you see pictures, you don't usually know what it's called.\n",
            "112.48 - 116.32000000000001 :   So when you read a magazine or you get the knowledge, that's where you get to know\n",
            "116.32000000000001 - 121.04 :   oh, this fabric is called this or this decoration is called that.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "segments"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixs0P3ZbnqHa",
        "outputId": "195ec452-0cf6-4cc7-fcfd-e84629db0d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'start': 0.0, 'end': 3.92},\n",
              " {'start': 3.92, 'end': 7.04},\n",
              " {'start': 7.04, 'end': 12.8},\n",
              " {'start': 12.8, 'end': 20.96},\n",
              " {'start': 20.96, 'end': 26.8},\n",
              " {'start': 26.8, 'end': 31.12},\n",
              " {'start': 31.12, 'end': 37.2},\n",
              " {'start': 37.2, 'end': 43.6},\n",
              " {'start': 43.6, 'end': 50.64},\n",
              " {'start': 50.64, 'end': 54.24},\n",
              " {'start': 54.24, 'end': 56.56},\n",
              " {'start': 56.56, 'end': 62.96},\n",
              " {'start': 63.84, 'end': 68.32000000000001},\n",
              " {'start': 69.2, 'end': 73.6},\n",
              " {'start': 74.48, 'end': 80.64},\n",
              " {'start': 81.44, 'end': 86.32000000000001},\n",
              " {'start': 86.32000000000001, 'end': 94.08000000000001},\n",
              " {'start': 94.08000000000001, 'end': 98.32000000000001},\n",
              " {'start': 98.32000000000001, 'end': 104.48},\n",
              " {'start': 104.48, 'end': 109.12},\n",
              " {'start': 109.12, 'end': 112.48},\n",
              " {'start': 112.48, 'end': 116.32000000000001},\n",
              " {'start': 116.32000000000001, 'end': 121.04}]"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've obtained the proper segments thanks to whisper. Let's check how many segments it created."
      ],
      "metadata": {
        "id": "kUFZqvEcn2t8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(segments)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ih21z-cn_yt",
        "outputId": "c2b781ec-007c-4ce7-a3cc-244cc65f16b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, whisper broke down the audion into 23 segments. We now need to pass these segments to the speechbrain model for extracting the speaker embeddings."
      ],
      "metadata": {
        "id": "YI6eDI_DoBWT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7.** Use the **speechbrain/spkrec-ecapa-voxceleb** model for speaker embedding extraction. What is the dimension of the speaker embeddings?"
      ],
      "metadata": {
        "id": "wtFtHtP-rWc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_embedding(audio_file, segment, duration, embedding_model):\n",
        "    \"\"\"Create speaker embedding for an audio segment.\"\"\"\n",
        "    audio = Audio()\n",
        "    start = segment[\"start\"]\n",
        "    end = min(duration, segment[\"end\"])\n",
        "\n",
        "    clip = Segment(start, end)\n",
        "    waveform, _ = audio.crop(audio_file, clip)\n",
        "\n",
        "    # Creates speaker embeddings for a single segment using the speechbrain model\n",
        "    return embedding_model(waveform[None])"
      ],
      "metadata": {
        "id": "KQggKDN1rYpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets try creating an embedding for a segment."
      ],
      "metadata": {
        "id": "3d4ADgi0oeZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = create_embedding(audio_file_path, {\"start\": 0, \"end\": 3.92}, 3.92, embedding_model)\n",
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhhGm89aoXPc",
        "outputId": "7b764687-6cc7-4786-9a40-329d4300161f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-40.25594   ,  -8.491479  ,  -4.9949446 , -26.65534   ,\n",
              "          9.425489  , -15.619783  , -13.361435  ,  29.846088  ,\n",
              "        -34.676872  ,  -0.57370985,  26.041285  ,   4.015476  ,\n",
              "         26.022345  ,  -3.417672  ,   2.490573  , -32.552284  ,\n",
              "        -19.57991   ,   2.5500743 ,   3.753426  ,  -7.033936  ,\n",
              "         -1.5066743 ,   4.335468  ,  -5.859436  , -16.098492  ,\n",
              "         25.152824  ,  24.570328  ,   7.2257648 ,   2.2420256 ,\n",
              "        -15.459007  ,  -8.607247  ,  10.132063  ,   6.4293847 ,\n",
              "         -8.238471  ,  27.347834  ,  28.328703  , -10.379413  ,\n",
              "         27.164042  , -14.08712   ,  19.617268  , -17.926006  ,\n",
              "         21.622137  , -25.019194  , -22.539604  , -21.980099  ,\n",
              "         -3.8643553 , -11.392321  ,  13.730856  ,  -5.730925  ,\n",
              "        -16.300035  , -34.68206   ,  22.299427  , -16.448433  ,\n",
              "        -36.93051   ,  -0.21806128,  11.828444  ,  26.695143  ,\n",
              "        -12.675824  ,  26.536583  , -31.337332  , -34.932266  ,\n",
              "         -2.3158658 ,  -7.0365553 , -11.077013  ,  17.389788  ,\n",
              "          3.1042833 ,  15.487036  ,  -2.3360982 ,   6.9093213 ,\n",
              "         -7.0044494 , -11.007322  , -22.41486   , -34.239323  ,\n",
              "         11.869232  , -39.059532  ,  -5.340164  , -15.652691  ,\n",
              "        -16.818071  ,   1.2584162 , -35.098343  , -21.758488  ,\n",
              "         -1.1329315 ,  -5.2002864 ,  -7.236807  ,  -8.716294  ,\n",
              "         10.981239  ,  -8.490639  ,   4.2068777 ,  17.37348   ,\n",
              "        -38.859306  ,  22.242079  ,  -9.600999  ,  -4.0428767 ,\n",
              "        -34.841637  ,  16.591848  , -31.463488  ,  -4.7660694 ,\n",
              "        -11.510523  ,  16.763954  , -22.291367  ,  -1.3612881 ,\n",
              "        -12.680533  ,  43.1159    ,   0.42747065, -29.823896  ,\n",
              "        -32.55921   , -22.241947  ,   0.1861317 , -17.179619  ,\n",
              "         -3.971361  ,  37.36319   ,  -1.2881258 ,  11.686028  ,\n",
              "        -17.236975  ,  30.169142  , -39.545986  ,  31.10786   ,\n",
              "         15.662882  ,  39.739323  , -15.588224  ,  -2.0308068 ,\n",
              "        -37.453503  ,  11.722714  , -35.684456  , -11.665983  ,\n",
              "         12.5658865 ,  11.698764  ,  22.767508  ,  -1.822068  ,\n",
              "        -12.439624  ,  -6.643579  ,   0.7723106 ,  10.729298  ,\n",
              "         29.308626  ,   3.4512665 ,  -8.85039   ,  18.449282  ,\n",
              "         24.449326  ,  -6.753231  ,  19.803814  ,  23.516165  ,\n",
              "         38.665974  ,   0.66900074,   0.05309665, -28.44137   ,\n",
              "         12.068011  , -28.42795   ,  17.878101  ,  -8.708966  ,\n",
              "          9.713168  ,   0.658467  , -20.798073  ,  22.11788   ,\n",
              "        -16.141905  ,  29.220478  ,  14.256974  ,  -6.9191513 ,\n",
              "        -51.571842  ,  52.250134  ,   5.2678485 ,  12.0324745 ,\n",
              "         -6.476648  ,  17.317142  , -18.968298  ,  14.795875  ,\n",
              "          5.166627  , -11.035187  ,  -2.3206806 , -11.286262  ,\n",
              "          8.353642  ,   7.294917  ,   3.317883  ,  13.8029995 ,\n",
              "          4.0494084 ,  28.9363    , -25.699879  ,  12.158181  ,\n",
              "         33.610306  ,  -4.6494627 ,  30.950039  ,  26.552979  ,\n",
              "         15.1616955 ,  24.33073   , -16.002771  ,  24.453035  ,\n",
              "        -10.930183  ,   6.6476746 ,  -9.760311  ,   5.163206  ,\n",
              "        -10.654236  ,  10.299049  , -29.51961   ,  28.81098   ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDRAIsaGouIB",
        "outputId": "3f7cfdd6-2e0e-47b4-91fe-58c1da3c0ae6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 192)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try it out for another segment:"
      ],
      "metadata": {
        "id": "Whk1k_DVpEuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = create_embedding(audio_file_path, {'start': 20.96, 'end': 26.8}, 5.84, embedding_model)\n",
        "embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veS5BdVfoxjy",
        "outputId": "fe89e849-cb3b-4322-e609-e615d401c059"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ -0.97149867,  21.238972  ,  28.899313  ,  17.766155  ,\n",
              "        -13.545868  ,   9.704622  , -17.773632  ,   1.0380232 ,\n",
              "        -11.902727  , -16.154942  ,  13.99373   ,  17.203987  ,\n",
              "         16.769989  , -43.61952   ,  18.326788  ,  22.05579   ,\n",
              "        -13.35937   ,   8.561718  , -29.26869   ,  20.302916  ,\n",
              "         10.7621565 , -20.021696  ,   7.0849    , -35.765457  ,\n",
              "          9.299911  ,   0.32360032, -15.321062  ,   2.0194566 ,\n",
              "        -14.767116  ,   4.387259  ,  16.354015  ,  -5.409315  ,\n",
              "         -4.6615305 , -10.783706  ,  15.87705   , -11.084269  ,\n",
              "        -14.936838  ,   2.1695988 ,  -0.35953552, -11.899469  ,\n",
              "        -10.252263  ,  27.308075  , -31.043213  ,  -8.750173  ,\n",
              "          2.138279  ,  18.813904  ,   0.2733121 ,  14.902317  ,\n",
              "         40.943127  , -13.979475  , -16.672977  , -18.296595  ,\n",
              "         21.046278  ,  11.567109  ,  -1.9439539 , -34.326775  ,\n",
              "         -8.685527  , -17.75976   , -23.779284  ,  20.677973  ,\n",
              "         11.896134  ,  11.671444  ,  -1.239296  ,  20.51947   ,\n",
              "        -14.434538  ,  21.829859  ,  18.99273   ,   2.3396213 ,\n",
              "         26.962315  , -25.531628  ,  17.129604  ,   5.5891147 ,\n",
              "          5.400017  ,   6.8669686 ,   6.1435823 , -26.691431  ,\n",
              "          9.684511  ,   6.8199277 , -38.142357  ,  -4.975083  ,\n",
              "         -8.116584  ,   2.3427968 ,  30.813503  ,  44.06583   ,\n",
              "         13.510725  ,   2.6232896 , -27.489592  , -10.130962  ,\n",
              "         -4.5111656 ,  19.705557  ,   9.416323  ,  -5.3042855 ,\n",
              "          0.4669484 ,  -0.41183847,   3.2559307 ,  17.831362  ,\n",
              "          0.62658185, -19.184435  ,  -6.4476986 , -13.059852  ,\n",
              "         14.491943  ,  35.170536  ,   8.2816105 , -15.229322  ,\n",
              "         14.957681  ,   7.282987  , -29.63705   , -20.349203  ,\n",
              "         -1.4694082 ,  14.481156  ,   0.37958977,  18.335419  ,\n",
              "         23.106203  ,  -4.931695  ,   2.5975018 ,  -0.8380666 ,\n",
              "         -0.46086273,  25.69994   ,  -6.5442424 , -22.800835  ,\n",
              "         -1.888083  ,   4.5348487 , -33.144867  ,  -0.30807787,\n",
              "         17.31883   , -17.97693   ,   4.842213  , -14.498969  ,\n",
              "        -23.413372  , -14.604328  ,  19.694063  ,  15.402869  ,\n",
              "          0.642559  , -20.520967  ,   6.0737257 ,  23.140827  ,\n",
              "         -1.529576  ,  -0.23812126,  -6.227496  , -22.627766  ,\n",
              "         -1.7818656 ,  -2.5792007 ,  -5.2921734 , -14.13148   ,\n",
              "          3.075572  ,  10.380395  , -12.745594  , -24.077055  ,\n",
              "        -28.472263  ,   1.7260137 ,   9.312536  ,   5.2755556 ,\n",
              "         24.971191  ,  31.15459   , -10.168259  , -26.7975    ,\n",
              "        -37.07366   ,  -6.850501  , -47.319626  ,  10.169752  ,\n",
              "         30.266245  ,  -9.211173  ,  11.261656  ,  24.844084  ,\n",
              "         20.20261   , -14.640347  ,   3.3472085 , -27.363438  ,\n",
              "         14.095189  ,  25.709846  ,  -2.6075683 ,  13.856743  ,\n",
              "         -9.572301  , -10.389814  ,  -6.5522532 ,  -8.40498   ,\n",
              "         -3.5030067 , -16.471292  ,  21.862755  ,  15.9169655 ,\n",
              "        -10.478007  , -11.162147  ,  -4.876107  ,   2.6997063 ,\n",
              "          8.451716  ,  10.123502  ,  11.535612  , -31.672346  ,\n",
              "         10.073129  ,  -3.1111095 ,  -2.3441947 ,  11.959916  ]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U58iW-MGpBQl",
        "outputId": "03a0b68a-ec43-486f-9cb6-6dba66a4ed94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 192)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we can see that the embedding vector is of size **192**"
      ],
      "metadata": {
        "id": "Owoyu6oXowUz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q8.** How many languages are supported by the Whisper model?\n",
        "\n",
        "**A.** 100"
      ],
      "metadata": {
        "id": "lcg8kGseri_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q9.** Apply K-means clustering on the speaker embeddings with n clusters=3. Which two clusters are closest?\n",
        "\n",
        "\n",
        "- [x] 2,3\n",
        "- [ ] 1,2\n",
        "- [ ] 1,3\n"
      ],
      "metadata": {
        "id": "eEcrtsUurmuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import euclidean_distances"
      ],
      "metadata": {
        "id": "cwLBEqQ8xsk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_embeddings(audio_file, segments, duration, embedding_model, num_speakers):\n",
        "    \"\"\"Create and process embeddings for all segments.\"\"\"\n",
        "\n",
        "    # Create embeddings for each segment\n",
        "\n",
        "    # lets create an empty array of the required size for storing the embeddings\n",
        "    # each embedding is of size 192, so if you have say 23 segments, your embedding dimension size will be: 23 X 192\n",
        "    embeddings = np.zeros(shape=(len(segments), 192))\n",
        "    for i, segment in enumerate(segments):\n",
        "        embeddings[i] = create_embedding(audio_file, segment, duration, embedding_model)\n",
        "    embeddings = np.nan_to_num(embeddings) # replace NaN values with 0 in the embeddings\n",
        "\n",
        "    # Cluster embeddings to assign speakers\n",
        "    clustering = KMeans(n_clusters=num_speakers, random_state=42).fit(embeddings)\n",
        "    labels = clustering.labels_\n",
        "    cluster_centers = clustering.cluster_centers_\n",
        "\n",
        "    # Add speaker labels to segments\n",
        "    for i, segment in enumerate(segments):\n",
        "        segment[\"speaker\"] = f\"SPEAKER{labels[i] + 1}\"\n",
        "\n",
        "    # return both the embedding segments and cluster centers (needed for further processing)\n",
        "    return segments, cluster_centers\n"
      ],
      "metadata": {
        "id": "-IfFJs5Droot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "segments, cluster_centers = process_embeddings(audio_file_path, segments, duration, embedding_model, num_speakers=3)\n",
        "segments"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2RC_LxMuhcj",
        "outputId": "3cc14841-4afa-4bd5-846a-ff128ec501f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'start': 0.0, 'end': 3.92, 'speaker': 'SPEAKER3'},\n",
              " {'start': 3.92, 'end': 7.04, 'speaker': 'SPEAKER1'},\n",
              " {'start': 7.04, 'end': 12.8, 'speaker': 'SPEAKER1'},\n",
              " {'start': 12.8, 'end': 20.96, 'speaker': 'SPEAKER1'},\n",
              " {'start': 20.96, 'end': 26.8, 'speaker': 'SPEAKER1'},\n",
              " {'start': 26.8, 'end': 31.12, 'speaker': 'SPEAKER2'},\n",
              " {'start': 31.12, 'end': 37.2, 'speaker': 'SPEAKER1'},\n",
              " {'start': 37.2, 'end': 43.6, 'speaker': 'SPEAKER1'},\n",
              " {'start': 43.6, 'end': 50.64, 'speaker': 'SPEAKER1'},\n",
              " {'start': 50.64, 'end': 54.24, 'speaker': 'SPEAKER1'},\n",
              " {'start': 54.24, 'end': 56.56, 'speaker': 'SPEAKER2'},\n",
              " {'start': 56.56, 'end': 62.96, 'speaker': 'SPEAKER1'},\n",
              " {'start': 63.84, 'end': 68.32000000000001, 'speaker': 'SPEAKER1'},\n",
              " {'start': 69.2, 'end': 73.6, 'speaker': 'SPEAKER1'},\n",
              " {'start': 74.48, 'end': 80.64, 'speaker': 'SPEAKER1'},\n",
              " {'start': 81.44, 'end': 86.32000000000001, 'speaker': 'SPEAKER2'},\n",
              " {'start': 86.32000000000001, 'end': 94.08000000000001, 'speaker': 'SPEAKER1'},\n",
              " {'start': 94.08000000000001, 'end': 98.32000000000001, 'speaker': 'SPEAKER1'},\n",
              " {'start': 98.32000000000001, 'end': 104.48, 'speaker': 'SPEAKER1'},\n",
              " {'start': 104.48, 'end': 109.12, 'speaker': 'SPEAKER1'},\n",
              " {'start': 109.12, 'end': 112.48, 'speaker': 'SPEAKER1'},\n",
              " {'start': 112.48, 'end': 116.32000000000001, 'speaker': 'SPEAKER1'},\n",
              " {'start': 116.32000000000001, 'end': 121.04, 'speaker': 'SPEAKER1'}]"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we just need to clean up this output a little, and merge the continuous sections which don't have a change of speaker into one section."
      ],
      "metadata": {
        "id": "YrrPPnThzUOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_output_dataframe(segments):\n",
        "    \"\"\"Create a DataFrame with speaker segments.\"\"\"\n",
        "    output = {\n",
        "        'Start': [],\n",
        "        'End': [],\n",
        "        'Speaker': []\n",
        "    }\n",
        "\n",
        "    for i, segment in enumerate(segments):\n",
        "        # Add new entry when speaker changes or at the start\n",
        "        if i == 0 or segments[i-1][\"speaker\"] != segment[\"speaker\"]:\n",
        "            output['Start'].append(str(convert_time(segment[\"start\"])))\n",
        "            output['Speaker'].append(segment['speaker'])\n",
        "            if i != 0:\n",
        "                output['End'].append(str(convert_time(segments[i-1]['end'])))\n",
        "\n",
        "    # Add final end time\n",
        "    output['End'].append(str(convert_time(segments[-1]['end'])))\n",
        "\n",
        "    return pd.DataFrame(output)"
      ],
      "metadata": {
        "id": "iS4ryZRuzO1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_output_dataframe(segments)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "yRoBIw_wzWyP",
        "outputId": "57d61083-30ff-42ef-e196-59234c9c7ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Start      End   Speaker\n",
              "0  0:00:00  0:00:04  SPEAKER3\n",
              "1  0:00:04  0:00:27  SPEAKER1\n",
              "2  0:00:27  0:00:31  SPEAKER2\n",
              "3  0:00:31  0:00:54  SPEAKER1\n",
              "4  0:00:54  0:00:57  SPEAKER2\n",
              "5  0:00:57  0:01:21  SPEAKER1\n",
              "6  0:01:21  0:01:26  SPEAKER2\n",
              "7  0:01:26  0:02:01  SPEAKER1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18933483-0e38-4c45-805b-1d004435fdb1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Start</th>\n",
              "      <th>End</th>\n",
              "      <th>Speaker</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0:00:00</td>\n",
              "      <td>0:00:04</td>\n",
              "      <td>SPEAKER3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0:00:04</td>\n",
              "      <td>0:00:27</td>\n",
              "      <td>SPEAKER1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0:00:27</td>\n",
              "      <td>0:00:31</td>\n",
              "      <td>SPEAKER2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0:00:31</td>\n",
              "      <td>0:00:54</td>\n",
              "      <td>SPEAKER1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0:00:54</td>\n",
              "      <td>0:00:57</td>\n",
              "      <td>SPEAKER2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0:00:57</td>\n",
              "      <td>0:01:21</td>\n",
              "      <td>SPEAKER1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0:01:21</td>\n",
              "      <td>0:01:26</td>\n",
              "      <td>SPEAKER2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0:01:26</td>\n",
              "      <td>0:02:01</td>\n",
              "      <td>SPEAKER1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18933483-0e38-4c45-805b-1d004435fdb1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-18933483-0e38-4c45-805b-1d004435fdb1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-18933483-0e38-4c45-805b-1d004435fdb1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5557ec51-7bfa-4a07-b247-2fb51d34d77d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5557ec51-7bfa-4a07-b247-2fb51d34d77d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5557ec51-7bfa-4a07-b247-2fb51d34d77d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"create_output_dataframe(segments)\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Start\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"0:00:04\",\n          \"0:00:57\",\n          \"0:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"End\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"0:00:27\",\n          \"0:01:21\",\n          \"0:00:04\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Speaker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"SPEAKER3\",\n          \"SPEAKER1\",\n          \"SPEAKER2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We also have the centroids of all the clusters in the variable \"cluster_centers\"\n",
        "# we can calculate the euclidean distance between all the 3 cluster centers to find\n",
        "# which two are the closest to each other\n",
        "\n",
        "c1 = cluster_centers[0]\n",
        "c2 = cluster_centers[1]\n",
        "c3 = cluster_centers[2]\n",
        "\n",
        "euclidean_distances([c1, c2, c3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJHV1nzI248o",
        "outputId": "ca55e34f-4af8-45bf-dccf-8c617156bf27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0.        , 319.397904  , 342.37442039],\n",
              "       [319.397904  ,   0.        , 196.5199781 ],\n",
              "       [342.37442039, 196.5199781 ,   0.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above matrix, we can see that distance betweeen the clusters 2 and 3 is the lowest according to euclidean dist."
      ],
      "metadata": {
        "id": "zLMVVSa23YTH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q10.** What is the cluster number assigned for the first 4 seconds of the audio when n clusters=3 and when n clusters=2?\n",
        "\n",
        "\n",
        "- [x] 3,2\n",
        "- [ ] 1,2\n"
      ],
      "metadata": {
        "id": "_S-h17PWrqeL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that when we use n_clusters = 3, the first 4 seconds get assigned to Cluster 3/Speaker 3.\n",
        "\n",
        "Let's try out the same when n_clusters = 2\n"
      ],
      "metadata": {
        "id": "z7Pr_cf6zp-O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# get the segments using whisper\n",
        "segments, duration = transcribe_audio(audio_file_path, \"base\")\n",
        "\n",
        "# get the extracted embedding segments using speech brain and cluster them\n",
        "segments, cluster_centers = process_embeddings(audio_file_path, segments, duration, embedding_model, num_speakers=2)\n",
        "\n",
        "# clean up the output and see the results of clustering\n",
        "create_output_dataframe(segments)"
      ],
      "metadata": {
        "id": "S2jiEfjvrq9P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "outputId": "f35aa258-41a0-46fd-9545-2e455d368422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 - 3.92 :   Let's talk about music. How often do you listen to music?\n",
            "3.92 - 7.04 :   I think I listen to music mostly when I'm driving.\n",
            "7.04 - 12.8 :   I think it puts me in such a good mood when I'm out there on a drive and I play my favorite\n",
            "12.8 - 20.96 :   music. I'm usually into Afro music a lot, hip-hop and Afro and R&B, so I prefer listening to music when\n",
            "20.96 - 26.8 :   I'm driving or sometimes when I'm working out at the gym, something like that.\n",
            "26.8 - 31.12 :   Is music an important subject in schools in your country?\n",
            "31.12 - 37.2 :   In schools in my country, it is because I'm from India, so in India,\n",
            "37.2 - 43.6 :   music and dance and expressing our emotions as usually through music and dancing.\n",
            "43.6 - 50.64 :   So in every school they teach classical music or they have a subject where there is something\n",
            "50.64 - 54.24 :   about music usually, so I think it is important.\n",
            "54.24 - 56.56 :   Do you ever go to live concerts?\n",
            "56.56 - 62.96 :   Oh, I've been to three concerts and three of them are my favorite artists and it was actually on my\n",
            "63.84 - 68.32000000000001 :   wish list and I made it happen and it was one of the best experiences.\n",
            "69.2 - 73.6 :   And in live concerts, it's a lot different than you would imagine.\n",
            "74.48 - 80.64 :   Just have to keep your energy straight and it's like you can't believe it's happening.\n",
            "81.44 - 86.32000000000001 :   Now let's talk about magazines and newspapers. Do you prefer to read magazines\n",
            "86.32000000000001 - 94.08000000000001 :   or newspapers? Definitely magazines, mostly on topics of fashion or interior design.\n",
            "94.08000000000001 - 98.32000000000001 :   This is what I really like because I like to see creative sides all from all over the world.\n",
            "98.32000000000001 - 104.48 :   I like to see what people are talking about, what's new and what's trending and I like to learn,\n",
            "104.48 - 109.12 :   like I like to have knowledge of things of like what is this called or what is that called?\n",
            "109.12 - 112.48 :   Because usually when you see pictures, you don't usually know what it's called.\n",
            "112.48 - 116.32000000000001 :   So when you read a magazine or you get the knowledge, that's where you get to know\n",
            "116.32000000000001 - 121.04 :   oh, this fabric is called this or this decoration is called that.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Start      End   Speaker\n",
              "0  0:00:00  0:00:04  SPEAKER2\n",
              "1  0:00:04  0:00:27  SPEAKER1\n",
              "2  0:00:27  0:00:31  SPEAKER2\n",
              "3  0:00:31  0:00:54  SPEAKER1\n",
              "4  0:00:54  0:00:57  SPEAKER2\n",
              "5  0:00:57  0:01:21  SPEAKER1\n",
              "6  0:01:21  0:01:26  SPEAKER2\n",
              "7  0:01:26  0:02:01  SPEAKER1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63bb13c6-cdb7-4f14-ae2b-e300cc73943c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Start</th>\n",
              "      <th>End</th>\n",
              "      <th>Speaker</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0:00:00</td>\n",
              "      <td>0:00:04</td>\n",
              "      <td>SPEAKER2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0:00:04</td>\n",
              "      <td>0:00:27</td>\n",
              "      <td>SPEAKER1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0:00:27</td>\n",
              "      <td>0:00:31</td>\n",
              "      <td>SPEAKER2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0:00:31</td>\n",
              "      <td>0:00:54</td>\n",
              "      <td>SPEAKER1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0:00:54</td>\n",
              "      <td>0:00:57</td>\n",
              "      <td>SPEAKER2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0:00:57</td>\n",
              "      <td>0:01:21</td>\n",
              "      <td>SPEAKER1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0:01:21</td>\n",
              "      <td>0:01:26</td>\n",
              "      <td>SPEAKER2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0:01:26</td>\n",
              "      <td>0:02:01</td>\n",
              "      <td>SPEAKER1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63bb13c6-cdb7-4f14-ae2b-e300cc73943c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-63bb13c6-cdb7-4f14-ae2b-e300cc73943c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-63bb13c6-cdb7-4f14-ae2b-e300cc73943c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-89d22057-16f2-47e1-b702-1224b64a0f4a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-89d22057-16f2-47e1-b702-1224b64a0f4a')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-89d22057-16f2-47e1-b702-1224b64a0f4a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"create_output_dataframe(segments)\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Start\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"0:00:04\",\n          \"0:00:57\",\n          \"0:00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"End\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"0:00:27\",\n          \"0:01:21\",\n          \"0:00:04\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Speaker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"SPEAKER1\",\n          \"SPEAKER2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, when we use n_clusters = 2, the first 4 seconds get assigned to speaker 2."
      ],
      "metadata": {
        "id": "5NIgk_9N4b0J"
      }
    }
  ]
}