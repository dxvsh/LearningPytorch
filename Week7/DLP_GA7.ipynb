{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4V+xz81HEJ0rPRcd4W+F/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dxvsh/LearningPytorch/blob/main/Week7/DLP_GA7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DLP GA7\n",
        "\n",
        "\n",
        "Instructions\n",
        "- pip install datasets transformers evaluate jiwer\n",
        "- import torch, import datasets, import evaluate, import numpy as np, from dataclasses import data class, field. from typing import Any, Dict, List, Optional, Union\n",
        "- load train and test splits of mozilla-foundation/common voice 11 0” assamese dataset\n",
        "- for test, take only first 10 examples and proceed (otherwise you will hit Out of Memory Error)\n",
        "- from transformers import WhisperFeatureExtractor\n",
        "- Load feature extractor from the pretrained whisper tiny of openai\n",
        "- from transformers import WhisperTokenizer\n",
        "- load tokenizer of openai whisper tiny for assamese for asr task\n",
        "- from transformers import WhisperProcessor\n",
        "- load processor of openai whisper tiny for assamese for asr task\n",
        "- from datasets import Audio\n",
        "- convert audio to sampling rate of 16k\n",
        "- write a function which takes batches of input data and gives batches with features    extracted and corresponding labels from the tokenizer.\n",
        "- from transformers import WhisperForConditionalGeneration\n",
        "- model = WhisperForConditionalGeneration.from pretrained(”openai/whisper-tiny”)\n",
        "- set language to assamese, task to asr and forced decoder ids to none\n",
        "- Write a data collator\n",
        "- import evaluate and set metric = evaluate.load(”wer”)\n",
        "- write a function def compute metrics(pred) which takes predictions and returns wer\n",
        "- from transformers import Seq2SeqTrainingArguments\n",
        "- set the arguments for Seq2SeqTrainingArguments() as mentioned in the link\n",
        "-https://huggingface.co/blog/fine-tune-whisper” but change warmup steps to 50, max steps to 100, per device train batch size=8, per device eval batch size=1, save steps=100, eval steps=100\n",
        "- from transformers import Seq2SeqTrainer\n",
        "- Set the arguments based on the info mentioned in the above link\n",
        "- start training\n"
      ],
      "metadata": {
        "id": "Ua2F6qpeSVOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets transformers evaluate jiwer > /dev/null"
      ],
      "metadata": {
        "id": "A8ldz-c-sKpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the train & test splits of the Assamese config of the [Common Voice Dataset](https://huggingface.co/datasets/mozilla-foundation/common_voice_11_0):"
      ],
      "metadata": {
        "id": "SbnJ6rUTwlKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset, DatasetDict\n",
        "\n",
        "common_voice_as = DatasetDict()\n",
        "\n",
        "# load the assamese train dataset\n",
        "common_voice_as['train'] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"as\", split=\"train\")\n",
        "\n",
        "# load the test dataset, take only the first 10 samples from the test dataset\n",
        "common_voice_as['test'] = load_dataset(\"mozilla-foundation/common_voice_11_0\", \"as\", split=\"test[:10]\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "snZv8bG1sRNH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "common_voice_as"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_8vL2Y4xqTE",
        "outputId": "be40227b-6ae0-4aeb-fb6f-f737c0cb989f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
              "        num_rows: 824\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['client_id', 'path', 'audio', 'sentence', 'up_votes', 'down_votes', 'age', 'gender', 'accent', 'locale', 'segment'],\n",
              "        num_rows: 10\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains lots of metadata which is not really required for our use case, so we can remove those columns:"
      ],
      "metadata": {
        "id": "lYWAVY8YxvUC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "common_voice_as = common_voice_as.remove_columns([\"accent\", \"age\", \"client_id\", \"down_votes\", \"gender\", \"locale\", \"path\", \"segment\", \"up_votes\"])"
      ],
      "metadata": {
        "id": "V7hufZTmxsQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "common_voice_as"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sV8Pf8ytWMM",
        "outputId": "5d3fa2fb-7253-4137-db96-723e099e7ca2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['audio', 'sentence'],\n",
              "        num_rows: 824\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['audio', 'sentence'],\n",
              "        num_rows: 10\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we're left with only the required features, the audio and its text transcript."
      ],
      "metadata": {
        "id": "He0YlC4SyPeh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.** How many examples are present in the train split of mozilla-foundation/common voice 11 0 ”assamese” langauge dataset ?"
      ],
      "metadata": {
        "id": "6Pz449dfUIuF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGBP3KsDSP4B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39abb9a1-1776-467a-9ee4-ccb3875e112f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "824"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(common_voice_as['train'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are **824** samples in the \"assamese\" config of the train split of the mozilla common voice dataset"
      ],
      "metadata": {
        "id": "Xs60kwskyriL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2.** How many unique characters are there in the train split text ?"
      ],
      "metadata": {
        "id": "CfPJJTI8UOWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined_text = \" \".join(common_voice_as['train']['sentence']) # combine all the text in the train set into a single string\n",
        "unique_chars = set(combined_text)\n",
        "len(unique_chars)"
      ],
      "metadata": {
        "id": "oBfitKYXUP5V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9307f9f-5064-4fdf-f26a-80abc8623186"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(unique_chars)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71zItaD20443",
        "outputId": "86ce1c26-42a9-4dcd-d299-72a76fad5343"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'“', 'য', 'ব', 'ু', 'ছ', 'ৈ', 'দ', 'আ', '‘', '”', 'ল', 'ঠ', 'ী', '.', 'ঙ', 'ৃ', 'ূ', 'ঔ', 'ো', 'ভ', 'ৎ', 'ধ', 'উ', 'এ', '়', 'ঢ', 'ঁ', 'ং', 'ঃ', 'ট', 'স', 'া', 'ঞ', 'ষ', 'ম', 'য়', 'জ', 'গ', 'ত', 'ৌ', '’', 'প', 'ই', '৷', '্', 'খ', 'ক', 'ঢ়', 'ৰ', ',', 'ড়', '-', \"'\", 'ঈ', 'অ', 'ন', 'হ', 'ফ', 'ৱ', 'ড', 'ি', 'থ', 'ও', 'ঘ', 'শ', '\"', 'ণ', 'র', '!', 'চ', ' ', '।', 'ে', '?'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are **74** unique characters in the train split of the dataset."
      ],
      "metadata": {
        "id": "keVDbThP1HQt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.** What is the sampling rate of the original mozilla-foundation/common voice 11 0 ”assamese” language audio in Hz?"
      ],
      "metadata": {
        "id": "akBy1TCwUQV8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's take a look at a sample from the dataset:"
      ],
      "metadata": {
        "id": "72Plk2v-1rPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "common_voice_as['train'][0]"
      ],
      "metadata": {
        "id": "7jMg7c_aUUm7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c0bcdec-5d9f-4c85-d068-9a363dff2a4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/fdcfd174c1db561f74a5aab292ff32458ceffd67c10de1ac5f5b77eae211090c/as_train_0/common_voice_as_22074894.mp3',\n",
              "  'array': array([ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
              "         -1.51620850e-06, -1.28747206e-06, -6.44893703e-07]),\n",
              "  'sampling_rate': 48000},\n",
              " 'sentence': 'দেখিলে যে অসমীয়া মানুহৰ জ্ঞান-উন্নতি পিনে অলপাে মনকাণ নাই'}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the original sampling rate is **48000** and the format of the audio files is **mp3**."
      ],
      "metadata": {
        "id": "u8p0kY101vz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "common_voice_as['train'].features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfTAC26I1vl5",
        "outputId": "6e0d2aa7-7518-4abd-9099-0c5a78b13c4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'audio': Audio(sampling_rate=48000, mono=True, decode=True, id=None),\n",
              " 'sentence': Value(dtype='string', id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4.** What is the format of the mozilla-foundation/common voice 11 0 ”assamese” language audio ?\n",
        "\n",
        "- [x] A. mp3\n",
        "- [ ] B. M4A\n",
        "- [ ] C. wav\n",
        "- [ ] D. FLAC\n"
      ],
      "metadata": {
        "id": "N1PMb9glUb4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "sqfWf2412Ikt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load whisper feature extractor"
      ],
      "metadata": {
        "id": "zSA2Yh-H2i6k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import WhisperFeatureExtractor\n",
        "\n",
        "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-tiny\")"
      ],
      "metadata": {
        "id": "CfbfqKM02Jgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load whisper tokenizer"
      ],
      "metadata": {
        "id": "TFYrOS0y3lNX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import WhisperTokenizer\n",
        "\n",
        "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-tiny\", language=\"Assamese\", task=\"transcribe\")"
      ],
      "metadata": {
        "id": "oz0kdbdl3lgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5.** What will be the window length in msec if n fft is 400 in ”WhisperFeatureExtractor” ?"
      ],
      "metadata": {
        "id": "XjXToKvlUijZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor"
      ],
      "metadata": {
        "id": "0sMD7YBIUmWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d4eefae-2def-4135-c9ec-4f87656c1ba1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WhisperFeatureExtractor {\n",
              "  \"chunk_length\": 30,\n",
              "  \"feature_extractor_type\": \"WhisperFeatureExtractor\",\n",
              "  \"feature_size\": 80,\n",
              "  \"hop_length\": 160,\n",
              "  \"n_fft\": 400,\n",
              "  \"n_samples\": 480000,\n",
              "  \"nb_max_frames\": 3000,\n",
              "  \"padding_side\": \"right\",\n",
              "  \"padding_value\": 0.0,\n",
              "  \"processor_class\": \"WhisperProcessor\",\n",
              "  \"return_attention_mask\": false,\n",
              "  \"sampling_rate\": 16000\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "window_length (ms) = (400 / 16000) * 1000 = 25 ms"
      ],
      "metadata": {
        "id": "HxSS6n7V_dpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6.** What is the first token number after tokenising the 56th example?"
      ],
      "metadata": {
        "id": "_y2Kj9jDUm2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_str = common_voice_as[\"train\"][56][\"sentence\"]\n",
        "labels = tokenizer(input_str).input_ids\n",
        "print(labels)\n",
        "decoded_with_special = tokenizer.decode(labels, skip_special_tokens=False)\n",
        "decoded_str = tokenizer.decode(labels, skip_special_tokens=True)\n",
        "\n",
        "print(f\"Input:                 {input_str}\")\n",
        "print(f\"Decoded w/ special:    {decoded_with_special}\")\n",
        "print(f\"Decoded w/out special: {decoded_str}\")\n",
        "print(f\"Are equal:             {input_str == decoded_str}\")\n"
      ],
      "metadata": {
        "id": "Dl0PkjdEUwhS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42b2c989-dad8-4a1a-d224-770e22a3c08e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50258, 50350, 50359, 50363, 29045, 103, 29045, 122, 29045, 101, 156, 11061, 29045, 97, 220, 29045, 237, 156, 100, 108, 29045, 123, 220, 29045, 101, 29045, 123, 29045, 99, 29045, 123, 220, 156, 2250, 29045, 123, 29045, 110, 156, 100, 108, 220, 29045, 103, 29045, 122, 156, 100, 108, 29045, 97, 220, 29045, 98, 29045, 243, 29045, 122, 220, 29045, 237, 29045, 253, 29045, 122, 220, 29045, 114, 29045, 123, 29045, 110, 29045, 97, 220, 29045, 98, 156, 100, 229, 29045, 243, 156, 100, 229, 29045, 248, 29045, 123, 220, 29045, 106, 29045, 122, 156, 100, 108, 29045, 123, 220, 29045, 110, 29045, 122, 29045, 117, 156, 100, 229, 29045, 243, 156, 8667, 220, 29045, 244, 29045, 122, 29045, 229, 220, 29045, 98, 29045, 107, 156, 15773, 8703, 97, 50257]\n",
            "Input:                 পানীত এৰি নিদি বিলৰ পাৰত থকা এটা শিলত থেকেচি মাৰি লাহেকৈ খাই থয়।\n",
            "Decoded w/ special:    <|startoftranscript|><|as|><|transcribe|><|notimestamps|>পানীত এৰি নিদি বিলৰ পাৰত থকা এটা শিলত থেকেচি মাৰি লাহেকৈ খাই থয়।<|endoftext|>\n",
            "Decoded w/out special: পানীত এৰি নিদি বিলৰ পাৰত থকা এটা শিলত থেকেচি মাৰি লাহেকৈ খাই থয়।\n",
            "Are equal:             True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPKYIJte8UC8",
        "outputId": "196a3672-28ac-43e3-d3d9-e1aba8e350a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50258"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first token number after tokenizing the 56th sample is 50258."
      ],
      "metadata": {
        "id": "oJ3ARMbu8Wts"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7.** What is the token corresponding to the token number 51833 in whisper?\n",
        "- [ ] A. < |89.38| >\n",
        "- [x] B. < |29.38| >\n",
        "- [ ] C. < |9.38| >\n",
        "- [ ] D. < |19.38| >\n"
      ],
      "metadata": {
        "id": "lXzMi0QvUoye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.convert_ids_to_tokens(51833)"
      ],
      "metadata": {
        "id": "tK7HGUgWU0F3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c92a9adb-20ba-44b2-8624-2d8a24dc43d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|29.38|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q8.** Is token number 51833 a special token?\n",
        "- [ ] A. Yes\n",
        "- [x] B. No"
      ],
      "metadata": {
        "id": "sLPcwWCrU1-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this list contains all the special tokens, so we can use it to make the check\n",
        "tokenizer.all_special_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8i2gsKou_8U3",
        "outputId": "75785009-338f-4b88-f860-a5e389360894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[50257,\n",
              " 50258,\n",
              " 50259,\n",
              " 50260,\n",
              " 50261,\n",
              " 50262,\n",
              " 50263,\n",
              " 50264,\n",
              " 50265,\n",
              " 50266,\n",
              " 50267,\n",
              " 50268,\n",
              " 50269,\n",
              " 50270,\n",
              " 50271,\n",
              " 50272,\n",
              " 50273,\n",
              " 50274,\n",
              " 50275,\n",
              " 50276,\n",
              " 50277,\n",
              " 50278,\n",
              " 50279,\n",
              " 50280,\n",
              " 50281,\n",
              " 50282,\n",
              " 50283,\n",
              " 50284,\n",
              " 50285,\n",
              " 50286,\n",
              " 50287,\n",
              " 50288,\n",
              " 50289,\n",
              " 50290,\n",
              " 50291,\n",
              " 50292,\n",
              " 50293,\n",
              " 50294,\n",
              " 50295,\n",
              " 50296,\n",
              " 50297,\n",
              " 50298,\n",
              " 50299,\n",
              " 50300,\n",
              " 50301,\n",
              " 50302,\n",
              " 50303,\n",
              " 50304,\n",
              " 50305,\n",
              " 50306,\n",
              " 50307,\n",
              " 50308,\n",
              " 50309,\n",
              " 50310,\n",
              " 50311,\n",
              " 50312,\n",
              " 50313,\n",
              " 50314,\n",
              " 50315,\n",
              " 50316,\n",
              " 50317,\n",
              " 50318,\n",
              " 50319,\n",
              " 50320,\n",
              " 50321,\n",
              " 50322,\n",
              " 50323,\n",
              " 50324,\n",
              " 50325,\n",
              " 50326,\n",
              " 50327,\n",
              " 50328,\n",
              " 50329,\n",
              " 50330,\n",
              " 50331,\n",
              " 50332,\n",
              " 50333,\n",
              " 50334,\n",
              " 50335,\n",
              " 50336,\n",
              " 50337,\n",
              " 50338,\n",
              " 50339,\n",
              " 50340,\n",
              " 50341,\n",
              " 50342,\n",
              " 50343,\n",
              " 50344,\n",
              " 50345,\n",
              " 50346,\n",
              " 50347,\n",
              " 50348,\n",
              " 50349,\n",
              " 50350,\n",
              " 50351,\n",
              " 50352,\n",
              " 50353,\n",
              " 50354,\n",
              " 50355,\n",
              " 50356,\n",
              " 50357,\n",
              " 50358,\n",
              " 50359,\n",
              " 50360,\n",
              " 50361,\n",
              " 50362,\n",
              " 50363]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "51833 in tokenizer.all_special_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMGj9qk3ADRx",
        "outputId": "9b1205b9-e59b-4275-f345-dcfd44c76b9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q9.** What is the token corresponding to the token number 50350 in whisper?\n",
        "- [ ] A. < |asp| >\n",
        "- [ ] B. < |s| >\n",
        "- [x] C. < |as| >\n",
        "- [ ] D. < |pa| >\n"
      ],
      "metadata": {
        "id": "k8ObX3iEU9-1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.convert_ids_to_tokens(50350)"
      ],
      "metadata": {
        "id": "7esooC9UVB35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "506db67c-a923-4a7e-8bbd-e685c69abd8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|as|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q10.** Is token number 50350 a special token?\n",
        "- [x] A. Yes\n",
        "- [ ] B. No\n"
      ],
      "metadata": {
        "id": "ijvvOPZQVDT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "50350 in tokenizer.all_special_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gg4F4kZj_WcC",
        "outputId": "af879f59-8e34-4170-dbba-52a23c5f1c2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    }
  ]
}